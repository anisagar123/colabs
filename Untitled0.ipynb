{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "18-1IT3ysh_pCczWfpDXDrSEDfeM_c0Ug",
      "authorship_tag": "ABX9TyNiukDPTnL+6J8jODDz9u8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anisagar123/colabs/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWhJQTQZI566"
      },
      "source": [
        "**FACIAL CLASSIFICATION PROBLEM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9r7AZOPJHBh"
      },
      "source": [
        "First we install Tensorflow for our work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMDIPNBcJRL1",
        "outputId": "c6bd9dbe-1805-4ed6-834d-ebf77e3ab23d",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow-gpu "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU1BQYc3JxGX"
      },
      "source": [
        "we can see that we have installed Tensorflow-gpu-2.3.1 one of the latest version of the Tenserflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq-CUQATJ_aa"
      },
      "source": [
        "Now we see the gpu allocated for our work we are expecting Tesla t4 gpu for this appication "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J29mkNCMJ9hl",
        "outputId": "89ac1e78-3f24-433a-888e-623b2de3cb8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 17 12:24:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540KwRRGKf-u"
      },
      "source": [
        "AS expected i got Tesla t4 for my working purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh6BdOrtLDJc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T-8-11hLg_G"
      },
      "source": [
        "Importing all required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SwzX6HwMy5I"
      },
      "source": [
        "image_size=[224,224]\n",
        "train=\"/content/drive/MyDrive/trainset\"\n",
        "test=\"/content/drive/MyDrive/testset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4raO86mL6cP"
      },
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "     shear_range=0.2,\n",
        "     zoom_range=0.2,\n",
        "     horizontal_flip=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nzYpWj1Mqy2"
      },
      "source": [
        "Augumenting the data set the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtAswZ50NR9M"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yicaX26gNgEU"
      },
      "source": [
        "rescaling the test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaiifS-JNlFC",
        "outputId": "229a7ced-0233-49b3-c41b-68bde4bd287a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator=train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=(224,224),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4199 images belonging to 1012 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2eKJoUO3ZZ",
        "outputId": "cf20f9f5-39ba-418c-8f88-a3e552e6da5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_generator=test_datagen.flow_from_directory(\n",
        "    test,\n",
        "    target_size=(224,224),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 115 images belonging to 21 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5jgr-ybZkD"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_OTmzhxbfK-",
        "outputId": "d2b2f8e7-5310-4f0c-9c10-d3164c0647f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "resnet = ResNet50(input_shape=image_size + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYjMYrsib04J"
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K-MvreWb2pK"
      },
      "source": [
        "x = Flatten()(resnet.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzlhFVTab_1I"
      },
      "source": [
        "prediction = Dense(len(train), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=resnet.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii36Ebf3b_zh",
        "outputId": "9ec5107f-4033-4e16-bfd2-df8d2b5df761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 31)           3110943     flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,698,655\n",
            "Trainable params: 3,110,943\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS2jh14bcg2w"
      },
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu4PJhqQcjZg"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-G8GdFfc45J",
        "outputId": "884c033a-8dca-4007-ce6b-68dc6b852a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(train,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 8,\n",
        "                                                 class_mode = 'categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4199 images belonging to 1012 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZv1gsSYdGS4",
        "outputId": "106092ee-24c3-4ea9-b6e1-0541e1af4cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(train,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 8,\n",
        "                                            class_mode = 'categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4199 images belonging to 1012 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s6iH-Nvg_mN",
        "outputId": "57748a8a-96fe-45a4-b274-c5d9795fac22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224,224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1012, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=1, steps_per_epoch=25, validation_data = train_generator, verbose = 1, validation_steps=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_55 (Conv2D)           (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 111, 111, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 109, 109, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 512)               9437696   \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1012)              519156    \n",
            "=================================================================\n",
            "Total params: 10,217,012\n",
            "Trainable params: 10,217,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "25/25 [==============================] - 79s 3s/step - loss: 6.9320 - accuracy: 0.0000e+00 - val_loss: 6.9333 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOJESbZYiHfP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNYliS_yj3q3",
        "outputId": "83b0ddbd-ecfb-4794-e688-d666f1f5001b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}